{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c99e4b1-7be4-497f-acb0-8427065f12d6",
   "metadata": {},
   "source": [
    "## Evaluate segmentation algorithm on HRF dataset\n",
    "https://medium.com/mlearning-ai/understanding-evaluation-metrics-in-medical-image-segmentation-d289a373a3f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b53388-de3c-4d42-b793-2b7a730d146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import retina_segment\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from statistics import mean \n",
    "from sklearn.metrics import (classification_report,\n",
    "                            roc_auc_score,\n",
    "                            f1_score,\n",
    "                            matthews_corrcoef,\n",
    "                            confusion_matrix, \n",
    "                            jaccard_score,\n",
    "                            recall_score,\n",
    "                            accuracy_score,\n",
    "                            confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11c8c86-e260-4e32-91e7-db1d50870b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_IMG_FOLDER = \"../Images/HRF/original/\"\n",
    "SEGMENT_IMG_FOLDER = \"../Images/HRF/manual_segment/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cd79c8-6cb8-474b-a203-b08f593a490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_IMGs = glob.glob(ORIGINAL_IMG_FOLDER+\"*\")\n",
    "SEGMENT_IMGs = glob.glob(SEGMENT_IMG_FOLDER+\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2ab349-b984-4aa1-8f2f-006bf7e40366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_ID(path):\n",
    "    ID = path.split(\"/\")[-1].split(\".\")[0]\n",
    "    return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314143a6-fafd-4a5e-981b-d56cbfdd287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_agg = []\n",
    "y_pred_agg = []\n",
    "\n",
    "accuracy_list = []\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "\n",
    "for image_path in ORIGINAL_IMGs:\n",
    "    ID = extract_img_ID(image_path)\n",
    "    #print(ID)\n",
    "    \n",
    "    # Load original image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Load segmented image, resize to match with segmentation output, select only green channel and flatten \n",
    "    img_segment = cv2.imread(SEGMENT_IMG_FOLDER+ID+\".tif\")\n",
    "    img_segment_1000 = cv2.resize(img_segment, (1000, 1000))\n",
    "    y_true = img_segment_1000[:,:,1].flatten() // 255\n",
    "\n",
    "    # Make prediction\n",
    "    y_pred = retina_segment.segmentation(img, resize=True)\n",
    "    y_pred = y_pred.flatten() // 255\n",
    "    #print(y_pred.size, y_true.size)\n",
    "\n",
    "    # Append the flattened arrays to the aggregated lists\n",
    "    y_true_agg.extend(y_true)\n",
    "    y_pred_agg.extend(y_pred)\n",
    "\n",
    "    # Compute metrics for single images\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    # Append results\n",
    "    accuracy_list.append(accuracy)\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a583ade-52fe-4a03-8d59-a3940eee9716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9524100888888889 Sensitivity: 0.7694500212044648 Specificity: 0.9655492781014003\n"
     ]
    }
   ],
   "source": [
    "# Average metrics\n",
    "print(\"Accuracy:\",mean(accuracy_list),\n",
    "      \"Sensitivity:\", mean(sensitivity_list),\n",
    "      \"Specificity:\",mean(specificity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a386de05-55eb-4277-9c44-4b34cacfe452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97  42030649\n",
      "           1       0.61      0.77      0.68   2969351\n",
      "\n",
      "    accuracy                           0.95  45000000\n",
      "   macro avg       0.80      0.87      0.83  45000000\n",
      "weighted avg       0.96      0.95      0.95  45000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the classification report for aggregated results\n",
    "aggregated_report = classification_report(y_true_agg, y_pred_agg)\n",
    "print(aggregated_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef449fb2-a508-43e1-a64d-5056b1e22eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient: 0.6803926004902283\n"
     ]
    }
   ],
   "source": [
    "dice = f1_score(y_true_agg, y_pred_agg)\n",
    "print(\"Dice Coefficient:\", dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f27215-a136-4842-a359-242b36a2014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8665690728213665\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true_agg, y_pred_agg)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c2815d-96f5-4a02-a6c2-8b353c975791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.660031094328147\n"
     ]
    }
   ],
   "source": [
    "mcc = matthews_corrcoef(y_true_agg, y_pred_agg)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982b3180-3d5a-4f52-81ae-0fe273a40319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.5156022925780737\n"
     ]
    }
   ],
   "source": [
    "jaccard = jaccard_score(y_true_agg, y_pred_agg)\n",
    "print(\"Jaccard:\", jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a7ec2-8979-49c5-87ca-4afbe0b489cc",
   "metadata": {},
   "source": [
    "### Parameters tuning\n",
    "\n",
    "(11, 250)\n",
    "{'dice': 0.6985778512305946, 'jaccard': 0.5367803613079382}\n",
    "\n",
    "(13, 100)\n",
    "{'dice': 0.7000099223826678, 'jaccard': 0.5384732810158603}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6216f651-a277-4630-9a12-edf210703078",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values = range(10, 15)  # range for t\n",
    "A_values = range(100, 500, 50)  # range for A\n",
    "#L_values = range(30, 71, 10)  # range for L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2595676-1a68-4d51-b760-a5a5dad811d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "\n",
    "for t_i in t_values:\n",
    "    for A_i in A_values:\n",
    "        #for L_i in L_values:\n",
    "\n",
    "            y_true_agg = []\n",
    "            y_pred_agg = []\n",
    "\n",
    "            for image_path in ORIGINAL_IMGs:\n",
    "                ID = extract_img_ID(image_path)\n",
    "                #print(ID)\n",
    "                \n",
    "                # Load original image\n",
    "                img = cv2.imread(image_path)\n",
    "                \n",
    "                # Load segmented image, resize to match with segmentation output, select only green channel and flatten \n",
    "                img_segment = cv2.imread(SEGMENT_IMG_FOLDER+ID+\".tif\")\n",
    "                img_segment_1000 = cv2.resize(img_segment, (1000, 1000))\n",
    "                y_true = img_segment_1000[:,:,1].flatten() // 255\n",
    "            \n",
    "                # Make prediction\n",
    "                y_pred = retina_segment.segmentation(img,t=t_i, A=A_i, resize=True)\n",
    "                y_pred = y_pred.flatten() // 255\n",
    "\n",
    "                # Append the flattened arrays to the aggregated lists\n",
    "                y_true_agg.extend(y_true)\n",
    "                y_pred_agg.extend(y_pred)\n",
    "\n",
    "            # Generate the classification report for aggregated results\n",
    "            # aggregated_report = classification_report(y_true_agg, y_pred_agg)\n",
    "            # auc = roc_auc_score(y_true_agg, y_pred_agg)\n",
    "            dice = f1_score(y_true_agg, y_pred_agg)\n",
    "            jaccard = jaccard_score(y_true_agg, y_pred_agg)\n",
    "\n",
    "\n",
    "            best_params[(t_i,A_i)] = {'dice':dice,'jaccard':jaccard} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e99c428c-3f44-4958-b931-501a37729883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n",
      "{'dice': 0.6919341146721166, 'jaccard': 0.5289749716992844}\n",
      "(10, 150)\n",
      "{'dice': 0.6942444290204283, 'jaccard': 0.5316802351450888}\n",
      "(10, 200)\n",
      "{'dice': 0.6957297783756524, 'jaccard': 0.5334245671186033}\n",
      "(10, 250)\n",
      "{'dice': 0.6959955136346362, 'jaccard': 0.5337370545208601}\n",
      "(10, 300)\n",
      "{'dice': 0.6961695025453988, 'jaccard': 0.5339417231798868}\n",
      "(10, 350)\n",
      "{'dice': 0.6961535691907562, 'jaccard': 0.5339229779987834}\n",
      "(10, 400)\n",
      "{'dice': 0.6962329186305973, 'jaccard': 0.5340163351104968}\n",
      "(10, 450)\n",
      "{'dice': 0.6959202253358181, 'jaccard': 0.5336485074427497}\n",
      "(11, 100)\n",
      "{'dice': 0.6972293849677988, 'jaccard': 0.53518967723306}\n",
      "(11, 150)\n",
      "{'dice': 0.6984310978937898, 'jaccard': 0.5366070876183215}\n",
      "(11, 200)\n",
      "{'dice': 0.6983721432695038, 'jaccard': 0.5365374900808555}\n",
      "(11, 250)\n",
      "{'dice': 0.6985778512305946, 'jaccard': 0.5367803613079382}\n",
      "(11, 300)\n",
      "{'dice': 0.6984553979222752, 'jaccard': 0.5366357762978646}\n",
      "(11, 350)\n",
      "{'dice': 0.6983193031464898, 'jaccard': 0.5364751162358813}\n",
      "(11, 400)\n",
      "{'dice': 0.6976449589460513, 'jaccard': 0.5356795474001256}\n",
      "(11, 450)\n",
      "{'dice': 0.6973614848743177, 'jaccard': 0.5353453600341567}\n",
      "(12, 100)\n",
      "{'dice': 0.6995409569439062, 'jaccard': 0.5379184839992938}\n",
      "(12, 150)\n",
      "{'dice': 0.699545242276902, 'jaccard': 0.53792355183636}\n",
      "(12, 200)\n",
      "{'dice': 0.6993923666928474, 'jaccard': 0.5377427817445989}\n",
      "(12, 250)\n",
      "{'dice': 0.699410990769815, 'jaccard': 0.5377648017983748}\n",
      "(12, 300)\n",
      "{'dice': 0.6987226284223111, 'jaccard': 0.5369513400322707}\n",
      "(12, 350)\n",
      "{'dice': 0.697774677899454, 'jaccard': 0.535832521497826}\n",
      "(12, 400)\n",
      "{'dice': 0.6967448427706361, 'jaccard': 0.5346189032175943}\n",
      "(12, 450)\n",
      "{'dice': 0.6958758639123032, 'jaccard': 0.5335963384589245}\n",
      "(13, 100)\n",
      "{'dice': 0.7000099223826678, 'jaccard': 0.5384732810158603}\n",
      "(13, 150)\n",
      "{'dice': 0.6992869859685662, 'jaccard': 0.5376181974232686}\n",
      "(13, 200)\n",
      "{'dice': 0.6986302173810978, 'jaccard': 0.5368422002047415}\n",
      "(13, 250)\n",
      "{'dice': 0.6982654423657154, 'jaccard': 0.5364115427915752}\n",
      "(13, 300)\n",
      "{'dice': 0.6971757066942654, 'jaccard': 0.5351264251645781}\n",
      "(13, 350)\n",
      "{'dice': 0.696012819503195, 'jaccard': 0.5337574095153463}\n",
      "(13, 400)\n",
      "{'dice': 0.694455762976982, 'jaccard': 0.5319281746902139}\n",
      "(13, 450)\n",
      "{'dice': 0.6928947880785049, 'jaccard': 0.5300987110746218}\n",
      "(14, 100)\n",
      "{'dice': 0.6996031044500448, 'jaccard': 0.5379919829431561}\n",
      "(14, 150)\n",
      "{'dice': 0.6979911294259199, 'jaccard': 0.5360878448686471}\n",
      "(14, 200)\n",
      "{'dice': 0.6971210990201007, 'jaccard': 0.5350620832801833}\n",
      "(14, 250)\n",
      "{'dice': 0.69595351152305, 'jaccard': 0.5336876542920512}\n",
      "(14, 300)\n",
      "{'dice': 0.6943306805339545, 'jaccard': 0.5317814167663076}\n",
      "(14, 350)\n",
      "{'dice': 0.692980368368592, 'jaccard': 0.5301988980101403}\n",
      "(14, 400)\n",
      "{'dice': 0.6909834963727747, 'jaccard': 0.5278646177936571}\n",
      "(14, 450)\n",
      "{'dice': 0.6894443614875984, 'jaccard': 0.5260702722016285}\n"
     ]
    }
   ],
   "source": [
    "for key in best_params.keys():\n",
    "    print(key)\n",
    "    print(best_params[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261e0af",
   "metadata": {},
   "source": [
    "## Test maintaining the aspect ratio (the length-to-height ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd717ef",
   "metadata": {},
   "source": [
    "### Fixed width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc3d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_agg = []\n",
    "y_pred_agg = []\n",
    "\n",
    "accuracy_list = []\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "\n",
    "# Desired width\n",
    "new_width = 1000\n",
    "\n",
    "for image_path in ORIGINAL_IMGs:\n",
    "    ID = extract_img_ID(image_path)\n",
    "    #print(ID)\n",
    "    \n",
    "    # Load original image\n",
    "    img = cv2.imread(image_path)\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # Calculate the aspect ratio (width/height)\n",
    "    #print(img.shape[1], img.shape[0])\n",
    "    aspect_ratio = img.shape[1] / img.shape[0]  # width/height\n",
    "    # Calculate the new height based on the aspect ratio\n",
    "    new_height = int(new_width / aspect_ratio)\n",
    "    \n",
    "    # Load segmented image, resize to match with segmentation output, select only green channel and flatten \n",
    "    img_segment = cv2.imread(SEGMENT_IMG_FOLDER+ID+\".tif\")\n",
    "    img_segment_1000 = cv2.resize(img_segment, (new_width, new_height))\n",
    "    #plt.imshow(img_segment_1000)\n",
    "    y_true = img_segment_1000[:,:,1].flatten() // 255\n",
    "\n",
    "    # Make prediction\n",
    "    y_pred = retina_segment.segmentation(img, resize=True,new_w= new_width, new_h=new_height)\n",
    "    #plt.imshow(y_pred)\n",
    "    y_pred = y_pred.flatten() // 255\n",
    "    #print(y_pred.size, y_true.size)\n",
    "\n",
    "    # Append the flattened arrays to the aggregated lists\n",
    "    y_true_agg.extend(y_true)\n",
    "    y_pred_agg.extend(y_pred)\n",
    "\n",
    "    # Compute metrics for single images\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    # Append results\n",
    "    accuracy_list.append(accuracy)\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5616a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9497981981981982 Sensitivity: 0.7495321140584095 Specificity: 0.9642048325779095\n"
     ]
    }
   ],
   "source": [
    "# Average metrics\n",
    "print(\"Accuracy:\",mean(accuracy_list),\n",
    "      \"Sensitivity:\", mean(sensitivity_list),\n",
    "      \"Specificity:\",mean(specificity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d406aad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97  27992158\n",
      "           1       0.60      0.75      0.66   1977842\n",
      "\n",
      "    accuracy                           0.95  29970000\n",
      "   macro avg       0.79      0.86      0.82  29970000\n",
      "weighted avg       0.96      0.95      0.95  29970000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the classification report for aggregated results\n",
    "aggregated_report = classification_report(y_true_agg, y_pred_agg)\n",
    "print(aggregated_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a865fc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient: 0.6626735847203744\n"
     ]
    }
   ],
   "source": [
    "dice = f1_score(y_true_agg, y_pred_agg)\n",
    "print(\"Dice Coefficient:\", dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a381441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8556541130607209\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true_agg, y_pred_agg)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1569b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.6407221748596614\n"
     ]
    }
   ],
   "source": [
    "mcc = matthews_corrcoef(y_true_agg, y_pred_agg)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01494624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.4955211959840141\n"
     ]
    }
   ],
   "source": [
    "jaccard = jaccard_score(y_true_agg, y_pred_agg)\n",
    "print(\"Jaccard:\", jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02444a68",
   "metadata": {},
   "source": [
    "### Fixed height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd964cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true_agg = []\n",
    "y_pred_agg = []\n",
    "\n",
    "accuracy_list = []\n",
    "sensitivity_list = []\n",
    "specificity_list = []\n",
    "\n",
    "# Desired height\n",
    "new_height = 1000\n",
    "\n",
    "for image_path in ORIGINAL_IMGs:\n",
    "    ID = extract_img_ID(image_path)\n",
    "    #print(ID)\n",
    "    \n",
    "    # Load original image\n",
    "    img = cv2.imread(image_path)\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # Calculate the aspect ratio (width/height)\n",
    "    aspect_ratio = img.shape[1] / img.shape[0]  # width/height\n",
    "    # Calculate the new width based on the aspect ratio\n",
    "    new_width = int(new_height * aspect_ratio)\n",
    "    \n",
    "    # Load segmented image, resize to match with segmentation output, select only green channel and flatten \n",
    "    img_segment = cv2.imread(SEGMENT_IMG_FOLDER+ID+\".tif\")\n",
    "    img_segment_1000 = cv2.resize(img_segment, (new_width, new_height))\n",
    "    #plt.imshow(img_segment_1000)\n",
    "    y_true = img_segment_1000[:,:,1].flatten() // 255\n",
    "\n",
    "    # Make prediction\n",
    "    y_pred = retina_segment.segmentation(img, resize=True,new_w= new_width, new_h=new_height)\n",
    "    #plt.imshow(y_pred)\n",
    "    y_pred = y_pred.flatten() // 255\n",
    "    #print(y_pred.size, y_true.size)\n",
    "\n",
    "    # Append the flattened arrays to the aggregated lists\n",
    "    y_true_agg.extend(y_true)\n",
    "    y_pred_agg.extend(y_pred)\n",
    "\n",
    "    # Compute metrics for single images\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    # Append results\n",
    "    accuracy_list.append(accuracy)\n",
    "    sensitivity_list.append(sensitivity)\n",
    "    specificity_list.append(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0d72a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956331525925926 Sensitivity: 0.7953333090301646 Specificity: 0.9678458290518002\n"
     ]
    }
   ],
   "source": [
    "# Average metrics\n",
    "print(\"Accuracy:\",mean(accuracy_list),\n",
    "      \"Sensitivity:\", mean(sensitivity_list),\n",
    "      \"Specificity:\",mean(specificity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6a68c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98  63046753\n",
      "           1       0.64      0.79      0.71   4453247\n",
      "\n",
      "    accuracy                           0.96  67500000\n",
      "   macro avg       0.81      0.88      0.84  67500000\n",
      "weighted avg       0.96      0.96      0.96  67500000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the classification report for aggregated results\n",
    "aggregated_report = classification_report(y_true_agg, y_pred_agg)\n",
    "print(aggregated_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f6afe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient: 0.7059234101615494\n"
     ]
    }
   ],
   "source": [
    "dice = f1_score(y_true_agg, y_pred_agg)\n",
    "print(\"Dice Coefficient:\", dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57a51aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8811041714632346\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_true_agg, y_pred_agg)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52652fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.687642859810086\n"
     ]
    }
   ],
   "source": [
    "mcc = matthews_corrcoef(y_true_agg, y_pred_agg)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c07c92c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.5455035781534964\n"
     ]
    }
   ],
   "source": [
    "jaccard = jaccard_score(y_true_agg, y_pred_agg)\n",
    "print(\"Jaccard:\", jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "981ccc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "# Desired height\n",
    "new_height = 1000\n",
    "\n",
    "for t_i in t_values:\n",
    "    for A_i in A_values:\n",
    "        #for L_i in L_values:\n",
    "\n",
    "            y_true_agg = []\n",
    "            y_pred_agg = []\n",
    "\n",
    "            for image_path in ORIGINAL_IMGs:\n",
    "                ID = extract_img_ID(image_path)\n",
    "                #print(ID)\n",
    "                \n",
    "                # Load original image\n",
    "                img = cv2.imread(image_path)\n",
    "                \n",
    "                # Calculate the aspect ratio (width/height)\n",
    "                aspect_ratio = img.shape[1] / img.shape[0]  # width/height\n",
    "                # Calculate the new width based on the aspect ratio\n",
    "                new_width = int(new_height * aspect_ratio)\n",
    "                \n",
    "                \n",
    "                # Load segmented image, resize to match with segmentation output, select only green channel and flatten \n",
    "                img_segment = cv2.imread(SEGMENT_IMG_FOLDER+ID+\".tif\")\n",
    "                img_segment_1000 = cv2.resize(img_segment, (new_width, new_height))\n",
    "                #plt.imshow(img_segment_1000)\n",
    "                y_true = img_segment_1000[:,:,1].flatten() // 255\n",
    "\n",
    "                # Make prediction\n",
    "                y_pred = retina_segment.segmentation(img,t=t_i, A=A_i, resize=True,new_w= new_width, new_h=new_height)\n",
    "                y_pred = y_pred.flatten() // 255\n",
    "\n",
    "                # Append the flattened arrays to the aggregated lists\n",
    "                y_true_agg.extend(y_true)\n",
    "                y_pred_agg.extend(y_pred)\n",
    "\n",
    "            # Generate the classification report for aggregated results\n",
    "            # aggregated_report = classification_report(y_true_agg, y_pred_agg)\n",
    "            # auc = roc_auc_score(y_true_agg, y_pred_agg)\n",
    "            dice = f1_score(y_true_agg, y_pred_agg)\n",
    "            jaccard = jaccard_score(y_true_agg, y_pred_agg)\n",
    "\n",
    "\n",
    "            best_params[(t_i,A_i)] = {'dice':dice,'jaccard':jaccard} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd4a4b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n",
      "{'dice': 0.7145658485134982, 'jaccard': 0.5558945572491286}\n",
      "(10, 150)\n",
      "{'dice': 0.717179056106649, 'jaccard': 0.5590640373628578}\n",
      "(10, 200)\n",
      "{'dice': 0.7183263726106942, 'jaccard': 0.56045966559668}\n",
      "(10, 250)\n",
      "{'dice': 0.7188017047442803, 'jaccard': 0.5610386053478253}\n",
      "(10, 300)\n",
      "{'dice': 0.7188292436898719, 'jaccard': 0.5610721600921926}\n",
      "(10, 350)\n",
      "{'dice': 0.7190477154912807, 'jaccard': 0.5613384075169165}\n",
      "(10, 400)\n",
      "{'dice': 0.7185718530430946, 'jaccard': 0.5607585994966132}\n",
      "(10, 450)\n",
      "{'dice': 0.718401143954063, 'jaccard': 0.560550706303309}\n",
      "(11, 100)\n",
      "{'dice': 0.7186613339607105, 'jaccard': 0.5608675934069364}\n",
      "(11, 150)\n",
      "{'dice': 0.7198283542793844, 'jaccard': 0.5622904996260788}\n",
      "(11, 200)\n",
      "{'dice': 0.7204227255196395, 'jaccard': 0.5630161928377517}\n",
      "(11, 250)\n",
      "{'dice': 0.7202129787445073, 'jaccard': 0.5627600270847928}\n",
      "(11, 300)\n",
      "{'dice': 0.7200139631709191, 'jaccard': 0.562517045072316}\n",
      "(11, 350)\n",
      "{'dice': 0.7193338387013686, 'jaccard': 0.5616872378137515}\n",
      "(11, 400)\n",
      "{'dice': 0.7188724614047842, 'jaccard': 0.5611248214936067}\n",
      "(11, 450)\n",
      "{'dice': 0.718438264529867, 'jaccard': 0.5605959078251604}\n",
      "(12, 100)\n",
      "{'dice': 0.7205111715512519, 'jaccard': 0.563124238001202}\n",
      "(12, 150)\n",
      "{'dice': 0.720720009570361, 'jaccard': 0.5633794126087373}\n",
      "(12, 200)\n",
      "{'dice': 0.7203551945043347, 'jaccard': 0.5629337073933638}\n",
      "(12, 250)\n",
      "{'dice': 0.7194647840428444, 'jaccard': 0.561846933280214}\n",
      "(12, 300)\n",
      "{'dice': 0.7191704099477098, 'jaccard': 0.5614879727430012}\n",
      "(12, 350)\n",
      "{'dice': 0.7181023768154788, 'jaccard': 0.5601869945211003}\n",
      "(12, 400)\n",
      "{'dice': 0.7170364962350244, 'jaccard': 0.558890797852639}\n",
      "(12, 450)\n",
      "{'dice': 0.7164655575137641, 'jaccard': 0.5581973757758723}\n",
      "(13, 100)\n",
      "{'dice': 0.7200554440302076, 'jaccard': 0.5625676836326973}\n",
      "(13, 150)\n",
      "{'dice': 0.7192142158791974, 'jaccard': 0.5615413793594711}\n",
      "(13, 200)\n",
      "{'dice': 0.7182428548828907, 'jaccard': 0.5603579879535351}\n",
      "(13, 250)\n",
      "{'dice': 0.7174420832534045, 'jaccard': 0.5593837704213048}\n",
      "(13, 300)\n",
      "{'dice': 0.7160207334743217, 'jaccard': 0.5576575511314941}\n",
      "(13, 350)\n",
      "{'dice': 0.7152796103675255, 'jaccard': 0.556758977392854}\n",
      "(13, 400)\n",
      "{'dice': 0.7142808257866852, 'jaccard': 0.5555496410977363}\n",
      "(13, 450)\n",
      "{'dice': 0.713468989036648, 'jaccard': 0.5545680461308148}\n",
      "(14, 100)\n",
      "{'dice': 0.7175845795851812, 'jaccard': 0.5595570422516178}\n",
      "(14, 150)\n",
      "{'dice': 0.7162371221314224, 'jaccard': 0.5579201069597726}\n",
      "(14, 200)\n",
      "{'dice': 0.7143575958319193, 'jaccard': 0.5556425282146547}\n",
      "(14, 250)\n",
      "{'dice': 0.7125072968352584, 'jaccard': 0.5534068621001645}\n",
      "(14, 300)\n",
      "{'dice': 0.7114176032917603, 'jaccard': 0.5520932189583831}\n",
      "(14, 350)\n",
      "{'dice': 0.7102206357412835, 'jaccard': 0.5506528135139402}\n",
      "(14, 400)\n",
      "{'dice': 0.7087031968804977, 'jaccard': 0.5488305981772892}\n",
      "(14, 450)\n",
      "{'dice': 0.7072860559207063, 'jaccard': 0.5471326886819147}\n"
     ]
    }
   ],
   "source": [
    "for key in best_params.keys():\n",
    "    print(key)\n",
    "    print(best_params[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116ad17",
   "metadata": {},
   "source": [
    "(11, 200)\n",
    "{'dice': 0.7204227255196395, 'jaccard': 0.5630161928377517}\n",
    "\n",
    "(12, 150)\n",
    "{'dice': 0.720720009570361, 'jaccard': 0.5633794126087373}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f57a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
